{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0dac238-fee8-4133-bdd9-8c746c6c0cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.ops import gen_audio_ops as audio_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d885f66-abff-418b-bbf9-1e690fdeca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label_classes = [\"_silence_\", \"_unknown_\", \"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\",\"nine\",\"zero\"]\n",
    "\n",
    "def load_wav_file(wav_filename, desired_samples=16000, clip_len_s=1):\n",
    "    decoded_wav_list = []\n",
    "    wav_file = tf.io.read_file(wav_filename)\n",
    "    decoded_wav = audio_ops.decode_wav(wav_file, desired_channels=1)\n",
    "    #print(len(decoded_wav[0]))\n",
    "    \n",
    "    for i in range(0, len(decoded_wav[0])//(desired_samples*clip_len_s)):\n",
    "        wav_file_clip = decoded_wav[0][i*(desired_samples*clip_len_s):(i+1)*(desired_samples*clip_len_s)]\n",
    "        decoded_wav_list.append(wav_file_clip)\n",
    "\n",
    "    return decoded_wav_list, decoded_wav.sample_rate\n",
    "\n",
    "def calculate_mfcc(audio_signal, audio_sample_rate, window_size, window_stride, num_mfcc):\n",
    "    \n",
    "    spectrogram = audio_ops.audio_spectrogram(input=audio_signal, window_size=window_size, stride=window_stride, magnitude_squared=True)\n",
    "\n",
    "    mfcc_features = audio_ops.mfcc(spectrogram, audio_sample_rate, dct_coefficient_count=num_mfcc)\n",
    "\n",
    "    return mfcc_features\n",
    "    \n",
    "def calculate_accuracy(predicted_indices, expected_indices):\n",
    "    correct_prediction = tf.equal(predicted_indices, expected_indices)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10346b5b-5f90-40a9-bf5e-7aaaaa6afc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_path(wav_filename, clip_duration_ms=1000):\n",
    "    desired_samples = int(16000 * clip_duration_ms / 1000)\n",
    "    decoded_wav_list, sample_rate = load_wav_file(wav_filename, desired_samples)\n",
    "\n",
    "    window_size_samples = int(sample_rate * 40 / 1000)\n",
    "    window_stride_samples = int(sample_rate * 20 / 1000)\n",
    "    dct_coefficient_count = 10\n",
    "\n",
    "    mfcc_list = []\n",
    "    for decoded_wav in decoded_wav_list:\n",
    "        mfcc = calculate_mfcc(decoded_wav, sample_rate, window_size_samples, window_stride_samples, dct_coefficient_count)\n",
    "        mfcc = tf.reshape(mfcc, [-1])\n",
    "        mfcc_list.append(mfcc)\n",
    "\n",
    "    return mfcc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c7e8ce0-5fd3-4fcf-a2a3-21f120872adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tflite_inference_class:\n",
    "    def __init__(self, tflite_path):\n",
    "        self.tflite_path = tflite_path\n",
    "        self.interpreter = self.init_tflite_model()\n",
    "        self.input_details = self.interpreter.get_input_details()\n",
    "        self.output_details = self.interpreter.get_output_details()\n",
    "        self.input_dtype = self.input_details[0][\"dtype\"]\n",
    "        self.output_dtype = self.output_details[0][\"dtype\"]\n",
    "        if self.input_dtype == np.int8:\n",
    "            self.input_scale, self.input_zero_point = self.input_details[0][\"quantization\"]\n",
    "        else:\n",
    "            self.input_scale, self.input_zero_point = 1, 0\n",
    "        if self.output_dtype == np.int8:\n",
    "            self.output_scale, self.output_zero_point = self.output_details[0][\"quantization\"]\n",
    "        else:\n",
    "            self.output_scale, self.output_zero_point = 1, 0\n",
    "\n",
    "    def init_tflite_model(self):\n",
    "        print(\"init_tflite_model\")\n",
    "        interpreter = tf.lite.Interpreter(model_path=self.tflite_path)\n",
    "        interpreter.allocate_tensors()\n",
    "        return interpreter    \n",
    "    def tflite_inference(self, input_data):\n",
    "        input_data = input_data / self.input_scale + self.input_zero_point\n",
    "        input_data = np.round(input_data) if self.input_dtype == np.int8 else input_data\n",
    "\n",
    "        self.interpreter.set_tensor(self.input_details[0]['index'], tf.cast(input_data, self.input_dtype))\n",
    "        self.interpreter.invoke()\n",
    "     \n",
    "        output_data = self.interpreter.get_tensor(self.output_details[0]['index'])\n",
    "        output_data = self.output_scale * (output_data.astype(np.float32) - self.output_zero_point)\n",
    "     \n",
    "        return output_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951e692b-bb9b-4a3b-a99c-2f0a66cec147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_wav(wav_filename, tflite_path, Label_classes):\n",
    "    mfcc_list = _process_path(wav_filename, clip_duration_ms=1000)\n",
    "    print(\"Total clips number: {}, and every clip is 1 (s)\".format(len(mfcc_list)))\n",
    "    print(\"Input dims: {}\".format(mfcc_list[0].shape.as_list()))\n",
    "    \n",
    "    predicted_indices = []\n",
    "    tflite_task = tflite_inference_class(tflite_path)\n",
    "    for mfcc in mfcc_list:\n",
    "        mfcc = tf.expand_dims(mfcc, axis=0)\n",
    "        #print(mfcc.shape.as_list())\n",
    "        prediction = tflite_task.tflite_inference(mfcc)\n",
    "        predicted_indices.append(np.squeeze(tf.argmax(prediction, axis=1)))\n",
    "    return predicted_indices\n",
    "\n",
    "def show_result(predicted_indices, Label_classes):\n",
    "    unique_elements, counts = np.unique(np.array(predicted_indices), return_counts=True)\n",
    "    fake_expected_indices = unique_elements[np.argmax(counts)]\n",
    "    #fake_expected_indices = 6 # Or you can assign a real ans here\n",
    "    print(f'Fake Label is {Label_classes[fake_expected_indices]}')\n",
    "    expected_indices = np.full(len(predicted_indices), fake_expected_indices)\n",
    "    \n",
    "    test_accuracy = calculate_accuracy(predicted_indices, expected_indices)\n",
    "    confusion_matrix = tf.math.confusion_matrix(expected_indices, predicted_indices, num_classes=12)\n",
    "    \n",
    "    print(f'Test accuracy = {test_accuracy * 100:.2f}%'f'(N={len(predicted_indices)})')\n",
    "    print(confusion_matrix.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364d52e8-48cc-4ca7-956e-be2f21431cc4",
   "metadata": {},
   "source": [
    "## Clean wav to kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53da4748-ecaa-4b08-9080-d58f2ae6edae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clips number: 60, and every clip is 1 (s)\n",
      "Input dims: [490]\n",
      "init_tflite_model\n",
      "Fake Label is one\n",
      "Test accuracy = 93.33%(N=60)\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3 56  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "wav_filename = r\"MS-SNSD\\kws_noisy_v1\\CleanSpeech_training_kws\\clnsp3.wav\"\n",
    "tflite_path = r\"ds_cnn_int8quant.tflite\"\n",
    "\n",
    "show_result(inference_wav(wav_filename, tflite_path, Label_classes), Label_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ae9d2-4abc-4bfe-b63d-488bd0449c59",
   "metadata": {},
   "source": [
    "## Noisy_db_0 + clean wav to kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67dd4493-d85f-4cba-86ab-8ed9e1ee7a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clips number: 60, and every clip is 1 (s)\n",
      "Input dims: [490]\n",
      "init_tflite_model\n",
      "Fake Label is one\n",
      "Test accuracy = 65.00%(N=60)\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  8 39  2  1  1  0  1  2  5  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "wav_filename = r\"MS-SNSD\\kws_noisy_v1\\NoisySpeech_training_kws\\noisy3_SNRdb_0.0_clnsp3.wav\"\n",
    "tflite_path = r\"ds_cnn_int8quant.tflite\"\n",
    "\n",
    "show_result(inference_wav(wav_filename, tflite_path, Label_classes), Label_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c38264-60a0-4c98-ba4f-ac08b383fea5",
   "metadata": {},
   "source": [
    "## Noisy_db_10 + clean wav to kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b96065a0-57af-4e6f-ab37-1269aec36ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clips number: 60, and every clip is 1 (s)\n",
      "Input dims: [490]\n",
      "init_tflite_model\n",
      "Fake Label is one\n",
      "Test accuracy = 73.33%(N=60)\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  8 44  1  0  1  0  2  1  3  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "wav_filename = r\"MS-SNSD\\kws_noisy_v1\\NoisySpeech_training_kws\\noisy3_SNRdb_10.0_clnsp3.wav\"\n",
    "tflite_path = r\"ds_cnn_int8quant.tflite\"\n",
    "\n",
    "show_result(inference_wav(wav_filename, tflite_path, Label_classes), Label_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b172e6d-2a24-4765-aadb-6d1984ae2931",
   "metadata": {},
   "source": [
    "## Noisy_db_20 + clean wav to kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61c37438-e7f0-4a09-9be9-94b499e60edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clips number: 60, and every clip is 1 (s)\n",
      "Input dims: [490]\n",
      "init_tflite_model\n",
      "Fake Label is one\n",
      "Test accuracy = 76.67%(N=60)\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  7 46  2  0  2  0  0  1  1  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "wav_filename = r\"MS-SNSD\\kws_noisy_v1\\NoisySpeech_training_kws\\noisy3_SNRdb_20.0_clnsp3.wav\"\n",
    "tflite_path = r\"ds_cnn_int8quant.tflite\"\n",
    "\n",
    "show_result(inference_wav(wav_filename, tflite_path, Label_classes), Label_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efb5023-7c31-4d0e-849a-9310a49e4cff",
   "metadata": {},
   "source": [
    "## Noisy_db_0 + clean wav to kws + rnn-noisy filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "994f9ad1-86d0-45ab-9e0c-559735c99446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clips number: 60, and every clip is 1 (s)\n",
      "Input dims: [490]\n",
      "init_tflite_model\n",
      "Fake Label is _silence_\n",
      "Test accuracy = 45.00%(N=60)\n",
      "[[27  1  1  1  1  1 19  0  0  1  8  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "wav_filename = r\"MS-SNSD\\kws_noisy_v1\\noisy1_SNRdb_0.0_clnsp1_filtered.wav\"\n",
    "tflite_path = r\"ds_cnn_int8quant.tflite\"\n",
    "\n",
    "show_result(inference_wav(wav_filename, tflite_path, Label_classes), Label_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47aceba-68aa-4382-9a57-24cd00c87f0a",
   "metadata": {},
   "source": [
    "## Original noisy sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a267f083-29e0-42e4-9c1d-6485fe42db4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clips number: 60, and every clip is 1 (s)\n",
      "Input dims: [490]\n",
      "init_tflite_model\n",
      "Fake Label is one\n",
      "Test accuracy = 83.33%(N=60)\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1 50  1  0  4  2  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "wav_filename = r\"_noisy_sample_kws.wav\"\n",
    "tflite_path = r\"ds_cnn_int8quant.tflite\"\n",
    "\n",
    "show_result(inference_wav(wav_filename, tflite_path, Label_classes), Label_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9397936-feef-40dc-8dde-4ef332966781",
   "metadata": {},
   "source": [
    "## Filtered sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c21da75-924e-4b4f-9d09-f71b9c6a57d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clips number: 60, and every clip is 1 (s)\n",
      "Input dims: [490]\n",
      "init_tflite_model\n",
      "Fake Label is one\n",
      "Test accuracy = 76.67%(N=60)\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  4 46  2  0  6  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "wav_filename = r\"_filtered_sample_kws.wav\"\n",
    "tflite_path = r\"ds_cnn_int8quant.tflite\"\n",
    "\n",
    "show_result(inference_wav(wav_filename, tflite_path, Label_classes), Label_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4cade9-cf42-4960-b7ed-2deef6b94af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a75f4c2-80b3-49bf-afc1-ba6d48b90463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved: noisy100_SNRdb_0.0_clnsp100.wav\n",
      "Moved: noisy10_SNRdb_0.0_clnsp10.wav\n",
      "Moved: noisy11_SNRdb_0.0_clnsp11.wav\n",
      "Moved: noisy12_SNRdb_0.0_clnsp12.wav\n",
      "Moved: noisy13_SNRdb_0.0_clnsp13.wav\n",
      "Moved: noisy14_SNRdb_0.0_clnsp14.wav\n",
      "Moved: noisy15_SNRdb_0.0_clnsp15.wav\n",
      "Moved: noisy16_SNRdb_0.0_clnsp16.wav\n",
      "Moved: noisy17_SNRdb_0.0_clnsp17.wav\n",
      "Moved: noisy18_SNRdb_0.0_clnsp18.wav\n",
      "Moved: noisy19_SNRdb_0.0_clnsp19.wav\n",
      "Moved: noisy1_SNRdb_0.0_clnsp1.wav\n",
      "Moved: noisy20_SNRdb_0.0_clnsp20.wav\n",
      "Moved: noisy21_SNRdb_0.0_clnsp21.wav\n",
      "Moved: noisy22_SNRdb_0.0_clnsp22.wav\n",
      "Moved: noisy23_SNRdb_0.0_clnsp23.wav\n",
      "Moved: noisy24_SNRdb_0.0_clnsp24.wav\n",
      "Moved: noisy25_SNRdb_0.0_clnsp25.wav\n",
      "Moved: noisy26_SNRdb_0.0_clnsp26.wav\n",
      "Moved: noisy27_SNRdb_0.0_clnsp27.wav\n",
      "Moved: noisy28_SNRdb_0.0_clnsp28.wav\n",
      "Moved: noisy29_SNRdb_0.0_clnsp29.wav\n",
      "Moved: noisy2_SNRdb_0.0_clnsp2.wav\n",
      "Moved: noisy30_SNRdb_0.0_clnsp30.wav\n",
      "Moved: noisy31_SNRdb_0.0_clnsp31.wav\n",
      "Moved: noisy32_SNRdb_0.0_clnsp32.wav\n",
      "Moved: noisy33_SNRdb_0.0_clnsp33.wav\n",
      "Moved: noisy34_SNRdb_0.0_clnsp34.wav\n",
      "Moved: noisy35_SNRdb_0.0_clnsp35.wav\n",
      "Moved: noisy36_SNRdb_0.0_clnsp36.wav\n",
      "Moved: noisy37_SNRdb_0.0_clnsp37.wav\n",
      "Moved: noisy38_SNRdb_0.0_clnsp38.wav\n",
      "Moved: noisy39_SNRdb_0.0_clnsp39.wav\n",
      "Moved: noisy3_SNRdb_0.0_clnsp3.wav\n",
      "Moved: noisy40_SNRdb_0.0_clnsp40.wav\n",
      "Moved: noisy41_SNRdb_0.0_clnsp41.wav\n",
      "Moved: noisy42_SNRdb_0.0_clnsp42.wav\n",
      "Moved: noisy43_SNRdb_0.0_clnsp43.wav\n",
      "Moved: noisy44_SNRdb_0.0_clnsp44.wav\n",
      "Moved: noisy45_SNRdb_0.0_clnsp45.wav\n",
      "Moved: noisy46_SNRdb_0.0_clnsp46.wav\n",
      "Moved: noisy47_SNRdb_0.0_clnsp47.wav\n",
      "Moved: noisy48_SNRdb_0.0_clnsp48.wav\n",
      "Moved: noisy49_SNRdb_0.0_clnsp49.wav\n",
      "Moved: noisy4_SNRdb_0.0_clnsp4.wav\n",
      "Moved: noisy50_SNRdb_0.0_clnsp50.wav\n",
      "Moved: noisy51_SNRdb_0.0_clnsp51.wav\n",
      "Moved: noisy52_SNRdb_0.0_clnsp52.wav\n",
      "Moved: noisy53_SNRdb_0.0_clnsp53.wav\n",
      "Moved: noisy54_SNRdb_0.0_clnsp54.wav\n",
      "Moved: noisy55_SNRdb_0.0_clnsp55.wav\n",
      "Moved: noisy56_SNRdb_0.0_clnsp56.wav\n",
      "Moved: noisy57_SNRdb_0.0_clnsp57.wav\n",
      "Moved: noisy58_SNRdb_0.0_clnsp58.wav\n",
      "Moved: noisy59_SNRdb_0.0_clnsp59.wav\n",
      "Moved: noisy5_SNRdb_0.0_clnsp5.wav\n",
      "Moved: noisy60_SNRdb_0.0_clnsp60.wav\n",
      "Moved: noisy61_SNRdb_0.0_clnsp61.wav\n",
      "Moved: noisy62_SNRdb_0.0_clnsp62.wav\n",
      "Moved: noisy63_SNRdb_0.0_clnsp63.wav\n",
      "Moved: noisy64_SNRdb_0.0_clnsp64.wav\n",
      "Moved: noisy65_SNRdb_0.0_clnsp65.wav\n",
      "Moved: noisy66_SNRdb_0.0_clnsp66.wav\n",
      "Moved: noisy67_SNRdb_0.0_clnsp67.wav\n",
      "Moved: noisy68_SNRdb_0.0_clnsp68.wav\n",
      "Moved: noisy69_SNRdb_0.0_clnsp69.wav\n",
      "Moved: noisy6_SNRdb_0.0_clnsp6.wav\n",
      "Moved: noisy70_SNRdb_0.0_clnsp70.wav\n",
      "Moved: noisy71_SNRdb_0.0_clnsp71.wav\n",
      "Moved: noisy72_SNRdb_0.0_clnsp72.wav\n",
      "Moved: noisy73_SNRdb_0.0_clnsp73.wav\n",
      "Moved: noisy74_SNRdb_0.0_clnsp74.wav\n",
      "Moved: noisy75_SNRdb_0.0_clnsp75.wav\n",
      "Moved: noisy76_SNRdb_0.0_clnsp76.wav\n",
      "Moved: noisy77_SNRdb_0.0_clnsp77.wav\n",
      "Moved: noisy78_SNRdb_0.0_clnsp78.wav\n",
      "Moved: noisy79_SNRdb_0.0_clnsp79.wav\n",
      "Moved: noisy7_SNRdb_0.0_clnsp7.wav\n",
      "Moved: noisy80_SNRdb_0.0_clnsp80.wav\n",
      "Moved: noisy81_SNRdb_0.0_clnsp81.wav\n",
      "Moved: noisy82_SNRdb_0.0_clnsp82.wav\n",
      "Moved: noisy83_SNRdb_0.0_clnsp83.wav\n",
      "Moved: noisy84_SNRdb_0.0_clnsp84.wav\n",
      "Moved: noisy85_SNRdb_0.0_clnsp85.wav\n",
      "Moved: noisy86_SNRdb_0.0_clnsp86.wav\n",
      "Moved: noisy87_SNRdb_0.0_clnsp87.wav\n",
      "Moved: noisy88_SNRdb_0.0_clnsp88.wav\n",
      "Moved: noisy89_SNRdb_0.0_clnsp89.wav\n",
      "Moved: noisy8_SNRdb_0.0_clnsp8.wav\n",
      "Moved: noisy90_SNRdb_0.0_clnsp90.wav\n",
      "Moved: noisy91_SNRdb_0.0_clnsp91.wav\n",
      "Moved: noisy92_SNRdb_0.0_clnsp92.wav\n",
      "Moved: noisy93_SNRdb_0.0_clnsp93.wav\n",
      "Moved: noisy94_SNRdb_0.0_clnsp94.wav\n",
      "Moved: noisy95_SNRdb_0.0_clnsp95.wav\n",
      "Moved: noisy96_SNRdb_0.0_clnsp96.wav\n",
      "Moved: noisy97_SNRdb_0.0_clnsp97.wav\n",
      "Moved: noisy98_SNRdb_0.0_clnsp98.wav\n",
      "Moved: noisy99_SNRdb_0.0_clnsp99.wav\n",
      "Moved: noisy9_SNRdb_0.0_clnsp9.wav\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "def move_files_with_pattern(source_dir, destination_dir, pattern=\"_0.0_\"):\n",
    "    # Ensure the destination directory exists, create it if not\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "    \n",
    "    # List all files in the source directory\n",
    "    files = os.listdir(source_dir)\n",
    "    \n",
    "    # Iterate through the files and move those that match the pattern\n",
    "    for file_name in files:\n",
    "        # Check if the file name contains the pattern\n",
    "        if pattern in file_name:\n",
    "            # Define the full file paths\n",
    "            source_file = os.path.join(source_dir, file_name)\n",
    "            destination_file = os.path.join(destination_dir, file_name)\n",
    "            \n",
    "            # Move the file\n",
    "            shutil.copy2(source_file, destination_file)\n",
    "            print(f\"Moved: {file_name}\")\n",
    "\n",
    "# Example usage\n",
    "source_directory = r'C:\\CYCHEN38\\MICRO_ML\\nnom\\examples\\rnn-denoise\\MS-SNSD\\kws_noisy_v1\\NoisySpeech_training_kws'\n",
    "destination_directory = r'C:\\CYCHEN38\\MICRO_ML\\NSNet\\dataset\\kws\\training\\noisy'\n",
    "\n",
    "# Move files containing \"_0.0_\" in their name\n",
    "move_files_with_pattern(source_directory, destination_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5f7a1d-4dc5-409a-8d4c-d1afba7959e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
